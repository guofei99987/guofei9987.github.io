---
layout: post
title: 【最优化工具箱】cvxopt
categories:
tags: 5_6_最优化
keywords:
description:
order: 7310
---

## matrix
```py
from cvxopt import matrix, solvers
cvxopt.matrix([[1.0,2.0]]) # 用list的话，生成的是2*1的矩阵，与一般的理解相反
cvxopt.matrix(np.array([[2,1]])) # 用array就正常
```

## lp：线性规划

$$\begin{array}{ll}
\min & c^Tx\\
s.t.& Gx\leq h\\
& Ax=b
\end{array}$$

```py
solvers.lp(c, G, h, A, b)
```




## qp：二次规划
[参考](https://blog.csdn.net/QW_sunny/article/details/79793889)  


代码：
```py
sv=cvxopt.solvers.qp(P,q,G,h,A,b)
sv['x'] # 就是最优解
```

标准形式：

$$\begin{array}{ll}
\min & (1/2)x^T Px+q^Tx\\
s.t.& Gx\leq h\\
& Ax=b
\end{array}$$


### 用二次规划做有约束岭回归

#### 1. 损失函数部分
损失函数是 $J=(\hat Y-Y)^T(\hat Y-Y)+\alpha w^Tw$  

先看第一项：  
$(\hat Y-Y)^T(\hat Y-Y)$  
$=\hat Y^T \hat Y-\hat Y^TY-Y^T\hat Y+Y^TY$（矩阵乘积结合律）  
$=\hat Y^T \hat Y-\hat Y^TY-\hat Y^T Y+Y^TY$（因为是1*1矩阵，所以可以随意转置）  
$=\hat Y^T \hat Y-2 Y^T \hat Y+Y^TY$

再看第二项：  
$\alpha w^Tw=\alpha w^T I w$（其中$I$表示单位矩阵：对角线全为1的对角阵）  

两项相加，并且考虑到 $Y^TY$ 是常数，在最优化中不重要。  
$J=\hat Y^T \hat Y-2 Y^T \hat Y+\alpha w^T I w$  
$=w^TX^TXw-2Y^TXw+\alpha w^T Iw$  
$=w^T(X^TX+\alpha I)w -2 (Y^TX)w$  
$=2[0.5w^T(X^TX+\alpha I)w -(Y^TX)w]$（写成二次规划的标准形式）  

令$p=X^TX+\alpha I,q^T=-Y^Tx$,  
得到二次型的标准形式：  
$\min\limits_w (1/2)w^T p w+q^Tw$  

#### 2. 约束部分
约束部分就按照标准形式写就行了，不需要公式转化。  

#### 3. 代码
```py
alpha=0.1 # l2范数前面的系数。
from cvxopt import matrix, solvers
X, y = matrix(X), matrix(y)

# 最优化目标部分：
I = matrix(np.eye(num_features))
P = X.T * X + alpha * I
q = (-1.0 * y.T * X).T # 因为标准型输入的是q.T，所以还需要一次转置

# 约束部分：(Gw<h)
G = matrix(g).T # 注意一下，这里的g是list，需要转置。如果g是np.array，就不需要。
h = matrix([-0.01] * G.size[0])  # 这里按照类似“小于即可”，“小0.01”等实际需求去自定义
# A,b 等号约束同理

sv = solvers.qp(p, q, G, h)
sv['x'] # 解出系数
```


## 未完待续

cvxopt这个包做优化似乎很强大，可以与scipy形成互补。  
所以有空把官方文档过一遍。  
